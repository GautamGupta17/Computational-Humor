{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa \n",
    "import math\n",
    "from glob import glob\n",
    "import argparse\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawClip3(object):\n",
    "    \"\"\"Loads audio clips from disk, applies a rolling window, and\n",
    "    extracts features from each sample.\"\"\"\n",
    "    featureFuncs = ['tonnetz', 'spectral_rolloff', 'spectral_contrast',\n",
    "                    'spectral_bandwidth', 'spectral_flatness', 'mfcc',\n",
    "                    'chroma_cqt', 'chroma_cens', 'melspectrogram']\n",
    "\n",
    "    def __init__(self, sourcefile, Y_class=None):\n",
    "        self.y, self.sr = sf.read(sourcefile)\n",
    "        self.laughs = None\n",
    "        self.Y_class = Y_class\n",
    "\n",
    "    def resample(self, rate, channel):\n",
    "        return librosa.resample(self.y.T[channel], self.sr, rate)\n",
    "\n",
    "    def amp(self, rate=22050, n_fft=2048, channel=0):\n",
    "        D = librosa.amplitude_to_db(librosa.magphase(librosa.stft(\n",
    "            self.resample(rate, channel), n_fft=n_fft))[0], ref=np.max)\n",
    "        return D\n",
    "\n",
    "    def _extract_feature(self, func):\n",
    "        method = getattr(librosa.feature, func)\n",
    "\n",
    "        # Construct params for each 'class' of features\n",
    "        params = {'y': self.raw}\n",
    "        if 'mfcc' in func:\n",
    "            params['sr'] = self.sr\n",
    "            params['n_mfcc'] = 128\n",
    "        if 'chroma' in func:\n",
    "            params['sr'] = self.sr\n",
    "\n",
    "        feature = method(**params)\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def _split_features_into_windows(self, data, duration):\n",
    "        # Apply a moving window\n",
    "        windows = []\n",
    "\n",
    "        # Pad the rightmost edge by repeating frames, simplifies stretching\n",
    "        # the model predictions to the original audio later on.\n",
    "        data = np.pad(data, [[0, duration], [0, 0]], mode='edge')\n",
    "        for i in range(data.shape[0] - duration):\n",
    "            windows.append(data[i:i + duration])\n",
    "\n",
    "        return np.array(windows)\n",
    "\n",
    "    def build_features(self, duration=30, milSamplesPerChunk=10):\n",
    "        # Extract features, one chunk at a time (to reduce memory required)\n",
    "        # Tip: about 65 million samples for a normal-length episode\n",
    "        # 10 million samples results in around 1.5GB to 2GB memory use\n",
    "        features = []\n",
    "\n",
    "        chunkLen = milSamplesPerChunk * 1000000\n",
    "        numChunks = math.ceil(self.y.shape[0] / chunkLen)\n",
    "\n",
    "        for i in range(numChunks):\n",
    "            # Set raw to the current chunk, for _extract_feature\n",
    "            self.raw = self.y.T[0][i * chunkLen:(i + 1) * chunkLen]\n",
    "\n",
    "            # For this chunk, run all of our feature extraction functions\n",
    "            # Each returned array is in the shape (features, steps)\n",
    "            # Use concatenate to combine (allfeatures, steps)\n",
    "            chunkFeatures = np.concatenate(\n",
    "                list(\n",
    "                    map(self._extract_feature, self.featureFuncs)\n",
    "                )\n",
    "            )\n",
    "            features.append(chunkFeatures)\n",
    "\n",
    "        # Transform to be consistent with our LSTM expected input\n",
    "        features = np.concatenate(features, axis=1).T\n",
    "        # Combine our chunks along the time-step axis.\n",
    "        features = self._split_features_into_windows(features, duration)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaughRemover(object):\n",
    "    \"\"\"Contains the logic to apply predictions as audio transformations\"\"\"\n",
    "    def __init__(self, kerasModel=None, kerasModelFile=None):\n",
    "        import keras\n",
    "        assert kerasModel or kerasModelFile\n",
    "        if kerasModel:\n",
    "            self.model = kerasModel\n",
    "        elif kerasModelFile:\n",
    "            self.model = keras.models.load_model(filepath=kerasModelFile)\n",
    "\n",
    "    def remove_dialogues(self, infile, outfile):\n",
    "        \"\"\"Remove laughs from a single sound file\"\"\"\n",
    "        rc = RawClip3(infile)\n",
    "        rc.laughs = self.model.predict(rc.build_features())\n",
    "        self._apply_laughs_array(rc.y, rc.sr, outfile, rc.laughs[:, 0])\n",
    "        return rc\n",
    "    \n",
    "    def remove_laughs(self, infile, outfile):\n",
    "        \"\"\"Remove laughs from a single sound file\"\"\"\n",
    "        rc = RawClip3(infile)\n",
    "        rc.laughs = self.model.predict(rc.build_features())\n",
    "        self._apply_laughs_array(rc.y, rc.sr, outfile, rc.laughs[:, 1])\n",
    "        return rc\n",
    "\n",
    "    def batch_remove_laughs(self, indir : str, outdir: str, batch_size: int=32):\n",
    "        \"\"\"Remove laughs from all files in a directory\"\"\"\n",
    "        # If indir == outdir, processes files in-place \n",
    "        batch_of_features = []\n",
    "        for filename in os.listdir(indir):\n",
    "            rc = RawClip3(os.path.join(indir, filename))\n",
    "            features = rc.build_features()\n",
    "            # Need to add some form of padding to each file so that it can be batched for keras.\n",
    "            # Then need to unpad so that original file duration is restored.\n",
    "            # Right now, it just loads the model once, and runs all the files through it one-by-one. \n",
    "            rc.laughs = self.model.predict(features)\n",
    "            self._apply_laughs_array(rc.y, rc.sr, os.path.join(outdir, filename), rc.laughs[:, 1])\n",
    "\n",
    "    def batch_remove_dialogues(self, indir : str, outdir: str, batch_size: int=32):\n",
    "        \"\"\"Remove laughs from all files in a directory\"\"\"\n",
    "        # If indir == outdir, processes files in-place \n",
    "        batch_of_features = []\n",
    "        for filename in os.listdir(indir):\n",
    "            rc = RawClip3(os.path.join(indir, filename))\n",
    "            features = rc.build_features()\n",
    "            # Need to add some form of padding to each file so that it can be batched for keras.\n",
    "            # Then need to unpad so that original file duration is restored.\n",
    "            # Right now, it just loads the model once, and runs all the files through it one-by-one. \n",
    "            rc.laughs = self.model.predict(features)\n",
    "            self._apply_laughs_array(rc.y, rc.sr, os.path.join(outdir, filename), rc.laughs[:, 0])\n",
    "\n",
    "\n",
    "    def _apply_laughs_array(self, y, sr, outfile, laughs):\n",
    "        y.T[0] = self._apply_frames_to_samples(frames=laughs, samples=y.T[0])\n",
    "\n",
    "        y.T[1] = self._apply_frames_to_samples(frames=laughs, samples=y.T[1])\n",
    "\n",
    "        sf.write(outfile, y, sr) \n",
    "\n",
    "    def _apply_frames_to_samples(self, frames, samples, exp=1, period=15):\n",
    "        # Apply a rolling average to smooth the laugh/notlaugh sections\n",
    "        frames = np.convolve(frames, np.ones((period,)) / period, mode='same')\n",
    "        # Each frame = default 512 samples, so expand over that period\n",
    "        frames = np.repeat(frames, librosa.core.frames_to_samples(1))\n",
    "        # Trim excess padding off the rightmost end\n",
    "        frames = frames[:len(samples)]\n",
    "        # Finally, apply audio volume change\n",
    "        return samples * (frames ** exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "Model = load_model('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_dialogues(sourceFile, outFile, model):\n",
    "    params = {}\n",
    "    if type(model) == str:\n",
    "        params['kerasModelFile'] = model\n",
    "    else:\n",
    "        params['kerasModel'] = model\n",
    "\n",
    "    laughr = LaughRemover(**params)\n",
    "\n",
    "    arr=laughr.remove_laughs(sourceFile, outFile)\n",
    "\n",
    "    return arr  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_laughs(sourceFile, outFile, model):\n",
    "    params = {}\n",
    "    if type(model) == str:\n",
    "        params['kerasModelFile'] = model\n",
    "    else:\n",
    "        params['kerasModel'] = model\n",
    "\n",
    "    laughr = LaughRemover(**params)\n",
    "\n",
    "    arr=laughr.remove_dialogues(sourceFile, outFile)\n",
    "\n",
    "    return arr  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_laughs(indir, outdir, model):\n",
    "    params = {}\n",
    "    if type(model) == str:\n",
    "        params['kerasModelFile'] = model\n",
    "    else:\n",
    "        params['kerasModel'] = model\n",
    "\n",
    "    laughr = LaughRemover(**params)\n",
    "\n",
    "    laughr.batch_remove_dialogues(indir, outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFunny_Data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mAudio_Files\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFunny_Audio_Files\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m#path to folder containing mp3 files of audio\u001b[39;00m\n\u001b[0;32m      5\u001b[0m dst \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFunny_Data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mAudio_Files\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mLabelling_Laugh_Audio\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m batch_laughs(path, dst, Model)\n",
      "Cell \u001b[1;32mIn[42], line 10\u001b[0m, in \u001b[0;36mbatch_laughs\u001b[1;34m(indir, outdir, model)\u001b[0m\n\u001b[0;32m      6\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mkerasModel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m model\n\u001b[0;32m      8\u001b[0m laughr \u001b[39m=\u001b[39m LaughRemover(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> 10\u001b[0m laughr\u001b[39m.\u001b[39;49mbatch_remove_dialogues(indir, outdir, Model)\n",
      "Cell \u001b[1;32mIn[36], line 44\u001b[0m, in \u001b[0;36mLaughRemover.batch_remove_dialogues\u001b[1;34m(self, indir, outdir, batch_size)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(indir):\n\u001b[0;32m     43\u001b[0m     rc \u001b[39m=\u001b[39m RawClip3(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(indir, filename))\n\u001b[1;32m---> 44\u001b[0m     features \u001b[39m=\u001b[39m rc\u001b[39m.\u001b[39;49mbuild_features()\n\u001b[0;32m     45\u001b[0m     \u001b[39m# Need to add some form of padding to each file so that it can be batched for keras.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[39m# Then need to unpad so that original file duration is restored.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[39m# Right now, it just loads the model once, and runs all the files through it one-by-one. \u001b[39;00m\n\u001b[0;32m     48\u001b[0m     rc\u001b[39m.\u001b[39mlaughs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(features)\n",
      "Cell \u001b[1;32mIn[35], line 65\u001b[0m, in \u001b[0;36mRawClip3.build_features\u001b[1;34m(self, duration, milSamplesPerChunk)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mT[\u001b[39m0\u001b[39m][i \u001b[39m*\u001b[39m chunkLen:(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m chunkLen]\n\u001b[0;32m     61\u001b[0m     \u001b[39m# For this chunk, run all of our feature extraction functions\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[39m# Each returned array is in the shape (features, steps)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[39m# Use concatenate to combine (allfeatures, steps)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     chunkFeatures \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(\n\u001b[1;32m---> 65\u001b[0m         \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m     66\u001b[0m             \u001b[39mmap\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_feature, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatureFuncs)\n\u001b[0;32m     67\u001b[0m         )\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     69\u001b[0m     features\u001b[39m.\u001b[39mappend(chunkFeatures)\n\u001b[0;32m     71\u001b[0m \u001b[39m# Transform to be consistent with our LSTM expected input\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[35], line 32\u001b[0m, in \u001b[0;36mRawClip3._extract_feature\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mchroma\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m func:\n\u001b[0;32m     30\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39msr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msr\n\u001b[1;32m---> 32\u001b[0m feature \u001b[39m=\u001b[39m method(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m     34\u001b[0m \u001b[39mreturn\u001b[39;00m feature\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\feature\\spectral.py:1475\u001b[0m, in \u001b[0;36mchroma_cqt\u001b[1;34m(y, sr, C, hop_length, fmin, norm, threshold, tuning, n_chroma, n_octaves, window, bins_per_octave, cqt_mode)\u001b[0m\n\u001b[0;32m   1472\u001b[0m \u001b[39m# Build the CQT if we don't have one already\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \u001b[39mif\u001b[39;00m C \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1474\u001b[0m     C \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(\n\u001b[1;32m-> 1475\u001b[0m         cqt_func[cqt_mode](\n\u001b[0;32m   1476\u001b[0m             y,\n\u001b[0;32m   1477\u001b[0m             sr\u001b[39m=\u001b[39;49msr,\n\u001b[0;32m   1478\u001b[0m             hop_length\u001b[39m=\u001b[39;49mhop_length,\n\u001b[0;32m   1479\u001b[0m             fmin\u001b[39m=\u001b[39;49mfmin,\n\u001b[0;32m   1480\u001b[0m             n_bins\u001b[39m=\u001b[39;49mn_octaves \u001b[39m*\u001b[39;49m bins_per_octave,\n\u001b[0;32m   1481\u001b[0m             bins_per_octave\u001b[39m=\u001b[39;49mbins_per_octave,\n\u001b[0;32m   1482\u001b[0m             tuning\u001b[39m=\u001b[39;49mtuning,\n\u001b[0;32m   1483\u001b[0m         )\n\u001b[0;32m   1484\u001b[0m     )\n\u001b[0;32m   1486\u001b[0m \u001b[39m# Map to chroma\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m cq_to_chr \u001b[39m=\u001b[39m filters\u001b[39m.\u001b[39mcq_to_chroma(\n\u001b[0;32m   1488\u001b[0m     C\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m],\n\u001b[0;32m   1489\u001b[0m     bins_per_octave\u001b[39m=\u001b[39mbins_per_octave,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1492\u001b[0m     window\u001b[39m=\u001b[39mwindow,\n\u001b[0;32m   1493\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\constantq.py:178\u001b[0m, in \u001b[0;36mcqt\u001b[1;34m(y, sr, hop_length, fmin, n_bins, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the constant-Q transform of an audio signal.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[39mThis implementation is based on the recursive sub-sampling method\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39m       [5.147e-02, 6.959e-02, ..., 1.694e-05, 5.811e-06]])\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39m# CQT is the special case of VQT with gamma=0\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m \u001b[39mreturn\u001b[39;00m vqt(\n\u001b[0;32m    179\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    180\u001b[0m     sr\u001b[39m=\u001b[39;49msr,\n\u001b[0;32m    181\u001b[0m     hop_length\u001b[39m=\u001b[39;49mhop_length,\n\u001b[0;32m    182\u001b[0m     fmin\u001b[39m=\u001b[39;49mfmin,\n\u001b[0;32m    183\u001b[0m     n_bins\u001b[39m=\u001b[39;49mn_bins,\n\u001b[0;32m    184\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m    185\u001b[0m     bins_per_octave\u001b[39m=\u001b[39;49mbins_per_octave,\n\u001b[0;32m    186\u001b[0m     tuning\u001b[39m=\u001b[39;49mtuning,\n\u001b[0;32m    187\u001b[0m     filter_scale\u001b[39m=\u001b[39;49mfilter_scale,\n\u001b[0;32m    188\u001b[0m     norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[0;32m    189\u001b[0m     sparsity\u001b[39m=\u001b[39;49msparsity,\n\u001b[0;32m    190\u001b[0m     window\u001b[39m=\u001b[39;49mwindow,\n\u001b[0;32m    191\u001b[0m     scale\u001b[39m=\u001b[39;49mscale,\n\u001b[0;32m    192\u001b[0m     pad_mode\u001b[39m=\u001b[39;49mpad_mode,\n\u001b[0;32m    193\u001b[0m     res_type\u001b[39m=\u001b[39;49mres_type,\n\u001b[0;32m    194\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    195\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\constantq.py:1045\u001b[0m, in \u001b[0;36mvqt\u001b[1;34m(y, sr, hop_length, fmin, n_bins, gamma, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         my_hop \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m   1044\u001b[0m         my_sr \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2.0\u001b[39m\n\u001b[1;32m-> 1045\u001b[0m         my_y \u001b[39m=\u001b[39m audio\u001b[39m.\u001b[39;49mresample(\n\u001b[0;32m   1046\u001b[0m             my_y, orig_sr\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, target_sr\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, res_type\u001b[39m=\u001b[39;49mres_type, scale\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   1047\u001b[0m         )\n\u001b[0;32m   1049\u001b[0m V \u001b[39m=\u001b[39m __trim_stack(vqt_resp, n_bins, dtype)\n\u001b[0;32m   1051\u001b[0m \u001b[39mif\u001b[39;00m scale:\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# Recompute lengths here because early downsampling may have changed\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m     \u001b[39m# our sampling rate\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:647\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    645\u001b[0m     y_hat \u001b[39m=\u001b[39m soxr\u001b[39m.\u001b[39mresample(y\u001b[39m.\u001b[39mT, orig_sr, target_sr, quality\u001b[39m=\u001b[39mres_type)\u001b[39m.\u001b[39mT\n\u001b[0;32m    646\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     y_hat \u001b[39m=\u001b[39m resampy\u001b[39m.\u001b[39;49mresample(y, orig_sr, target_sr, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49mres_type, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m fix:\n\u001b[0;32m    650\u001b[0m     y_hat \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mfix_length(y_hat, size\u001b[39m=\u001b[39mn_samples, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\resampy\\core.py:168\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         resample_f_s(\n\u001b[0;32m    159\u001b[0m             x\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[0;32m    160\u001b[0m             t_out,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m             y\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     resample_f_s(\n\u001b[0;32m    169\u001b[0m         x\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[0;32m    170\u001b[0m         t_out,\n\u001b[0;32m    171\u001b[0m         interp_win,\n\u001b[0;32m    172\u001b[0m         interp_delta,\n\u001b[0;32m    173\u001b[0m         precision,\n\u001b[0;32m    174\u001b[0m         scale,\n\u001b[0;32m    175\u001b[0m         y\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\np\\ufunc\\gufunc.py:192\u001b[0m, in \u001b[0;36mGUFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(sig)\n\u001b[0;32m    191\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_ufunc()\n\u001b[1;32m--> 192\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mufunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "from os import path\n",
    "\n",
    "path = \"Dataset\\Funny_Data\\Audio_Files\\Funny_Audio_Files\" #path to folder containing mp3 files of audio\n",
    "dst = \"Dataset\\Funny_Data\\Audio_Files\\Labelling_Laugh_Audio\"\n",
    "\n",
    "batch_laughs(path, dst, Model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below cell to get mute laughs from one audio clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorabh_Pant\n",
      "Sorabh_Pant_funny.wav\n",
      "Sorabh_Pant_dialogue.wav\n"
     ]
    }
   ],
   "source": [
    "path = 'Sorabh_Pant.wav'\n",
    "root_ext = os.path.splitext(path)\n",
    "print(root_ext[0])\n",
    "new_name = root_ext[0]+str('_funny.wav')\n",
    "renew_name = root_ext[0]+str('_dialogue.wav')\n",
    "print(new_name)\n",
    "print(renew_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do_laughs(sourceFile=path,                outFile=new_name, model=Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 40s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.RawClip3 at 0x16fe41ced70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_dialogues(sourceFile=path,\n",
    "                outFile=renew_name,\n",
    "                model=Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\\Funny_Data\\Audio_Files\\Funny_Audio_Files\\Kanan_Gill.wav\n",
      "Dataset\\Funny_Data\\Audio_Files\\Labelling_Laugh_Audio\\name.wav\n",
      "842/842 [==============================] - 31s 36ms/step\n",
      "Dataset\\Funny_Data\\Audio_Files\\Funny_Audio_Files\\Mark_Normand.wav\n",
      "Dataset\\Funny_Data\\Audio_Files\\Labelling_Laugh_Audio\\name.wav\n",
      "985/985 [==============================] - 27s 28ms/step\n",
      "Dataset\\Funny_Data\\Audio_Files\\Funny_Audio_Files\\Sorabh_Pant.wav\n",
      "Dataset\\Funny_Data\\Audio_Files\\Labelling_Laugh_Audio\\name.wav\n",
      "156/912 [====>.........................] - ETA: 29s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m name \u001b[39m=\u001b[39m dst \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(name)\n\u001b[1;32m---> 15\u001b[0m do_dialogues(sourceFile\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m     16\u001b[0m             outFile\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m     17\u001b[0m             model\u001b[39m=\u001b[39;49mModel)\n",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m, in \u001b[0;36mdo_dialogues\u001b[1;34m(sourceFile, outFile, model)\u001b[0m\n\u001b[0;32m      6\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mkerasModel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m model\n\u001b[0;32m      8\u001b[0m laughr \u001b[39m=\u001b[39m LaughRemover(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> 10\u001b[0m arr\u001b[39m=\u001b[39mlaughr\u001b[39m.\u001b[39;49mremove_laughs(sourceFile, outFile)\n\u001b[0;32m     12\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "Cell \u001b[1;32mIn[23], line 21\u001b[0m, in \u001b[0;36mLaughRemover.remove_laughs\u001b[1;34m(self, infile, outfile)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Remove laughs from a single sound file\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m rc \u001b[39m=\u001b[39m RawClip3(infile)\n\u001b[1;32m---> 21\u001b[0m rc\u001b[39m.\u001b[39mlaughs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(rc\u001b[39m.\u001b[39;49mbuild_features())\n\u001b[0;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_laughs_array(rc\u001b[39m.\u001b[39my, rc\u001b[39m.\u001b[39msr, outfile, rc\u001b[39m.\u001b[39mlaughs[:, \u001b[39m1\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m rc\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2350\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2348\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   2349\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2350\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[0;32m   2351\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2352\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\naren\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "from os import path\n",
    "\n",
    "path = \"Dataset\\Funny_Data\\Audio_Files\\Funny_Audio_Files\" #path to folder containing mp3 files of audio\n",
    "dst = \"Dataset\\Funny_Data\\Audio_Files\\Labelling_Laugh_Audio\"\n",
    "\n",
    "filenames = glob.glob(os.path.join(path, '*.wav'))\n",
    "filenames = sorted(filenames)\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    name = filename.split('\\\\')[-1]\n",
    "    name = name.split('.')[0]\n",
    "    name = dst + '\\\\name' + '.wav'\n",
    "    print(name)\n",
    "    do_dialogues(sourceFile=filename,\n",
    "                outFile=name,\n",
    "                model=Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25f5a0c83a496fdcf8d064ab469e301a06d19a0e1bbb7f82387ec11f7ef14d37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
