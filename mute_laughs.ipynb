{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import math\n",
    "from glob import glob\n",
    "import argparse\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawClip3(object):\n",
    "    \"\"\"Loads audio clips from disk, applies a rolling window, and\n",
    "    extracts features from each sample.\"\"\"\n",
    "    featureFuncs = ['tonnetz', 'spectral_rolloff', 'spectral_contrast',\n",
    "                    'spectral_bandwidth', 'spectral_flatness', 'mfcc',\n",
    "                    'chroma_cqt', 'chroma_cens', 'melspectrogram']\n",
    "\n",
    "    def __init__(self, sourcefile, Y_class=None):\n",
    "        self.y, self.sr = sf.read(sourcefile)\n",
    "        self.laughs = None\n",
    "        self.Y_class = Y_class\n",
    "\n",
    "    def resample(self, rate, channel):\n",
    "        return librosa.resample(self.y.T[channel], self.sr, rate)\n",
    "\n",
    "    def amp(self, rate=22050, n_fft=2048, channel=0):\n",
    "        D = librosa.amplitude_to_db(librosa.magphase(librosa.stft(\n",
    "            self.resample(rate, channel), n_fft=n_fft))[0], ref=np.max)\n",
    "        return D\n",
    "\n",
    "    def _extract_feature(self, func):\n",
    "        method = getattr(librosa.feature, func)\n",
    "\n",
    "        # Construct params for each 'class' of features\n",
    "        params = {'y': self.raw}\n",
    "        if 'mfcc' in func:\n",
    "            params['sr'] = self.sr\n",
    "            params['n_mfcc'] = 128\n",
    "        if 'chroma' in func:\n",
    "            params['sr'] = self.sr\n",
    "\n",
    "        feature = method(**params)\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def _split_features_into_windows(self, data, duration):\n",
    "        # Apply a moving window\n",
    "        windows = []\n",
    "\n",
    "        # Pad the rightmost edge by repeating frames, simplifies stretching\n",
    "        # the model predictions to the original audio later on.\n",
    "        data = np.pad(data, [[0, duration], [0, 0]], mode='edge')\n",
    "        for i in range(data.shape[0] - duration):\n",
    "            windows.append(data[i:i + duration])\n",
    "\n",
    "        return np.array(windows)\n",
    "\n",
    "    def build_features(self, duration=30, milSamplesPerChunk=10):\n",
    "        # Extract features, one chunk at a time (to reduce memory required)\n",
    "        # Tip: about 65 million samples for a normal-length episode\n",
    "        # 10 million samples results in around 1.5GB to 2GB memory use\n",
    "        features = []\n",
    "\n",
    "        chunkLen = milSamplesPerChunk * 1000000\n",
    "        numChunks = math.ceil(self.y.shape[0] / chunkLen)\n",
    "\n",
    "        for i in range(numChunks):\n",
    "            # Set raw to the current chunk, for _extract_feature\n",
    "            self.raw = self.y.T[0][i * chunkLen:(i + 1) * chunkLen]\n",
    "\n",
    "            # For this chunk, run all of our feature extraction functions\n",
    "            # Each returned array is in the shape (features, steps)\n",
    "            # Use concatenate to combine (allfeatures, steps)\n",
    "            chunkFeatures = np.concatenate(\n",
    "                list(\n",
    "                    map(self._extract_feature, self.featureFuncs)\n",
    "                )\n",
    "            )\n",
    "            features.append(chunkFeatures)\n",
    "\n",
    "        # Transform to be consistent with our LSTM expected input\n",
    "        features = np.concatenate(features, axis=1).T\n",
    "        # Combine our chunks along the time-step axis.\n",
    "        features = self._split_features_into_windows(features, duration)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25f5a0c83a496fdcf8d064ab469e301a06d19a0e1bbb7f82387ec11f7ef14d37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
